Assessment & Monitoring Plan
Evaluation framework using X→M→Y logic model

LOGIC MODEL (X→M→Y FRAMEWORK)

Independent Variable (X): The Intervention

X1: Heartfelt DEI Language - Authentic commitment statements in all job postings (100% of ~200 postings/year)
X2: Structured Hiring Processes - Standardized interview guides, blind resume review, diverse panels (90% interview compliance, 80% blind review)
X3: Voluntary Training + Transparency - Optional 2-hour bias workshops + monthly public dashboards (50%+ manager participation target)

Mediating Variables (M): How Change Happens

M1: Diverse Applicant Pool - X1 signals authentic commitment → underrepresented candidates apply → larger diverse pool increases hiring probability
M2: Reduced Bias - X2 removes discretion and demographic cues → evaluations based on job criteria not bias → fairer selection
M3: Intrinsic Motivation - X3 voluntary approach + transparency → managers internalize DEI values → sustained behavior change

Dependent Variable (Y): Outcomes

Y1 Primary: Diversity Hiring Rate - Baseline 24% → Target 29%+ (5-point increase) | Measured monthly via HRIS demographics
Y2: Quality of Hire - Baseline 4.0/5.0 → Target ≥4.0 (maintain, no quality trade-off) | 90-day manager ratings
Y3: Candidate Experience - Baseline 3.2-3.9 for underrepresented groups → Target ≥4.2 all groups | Post-interview surveys
Y4: Manager Confidence - Baseline 43% high confidence → Target 75%+ high confidence, 80%+ rate tools helpful | Quarterly surveys

X→M→Y Pathways
X1 (Heartfelt language) → M1 (Diverse applicant pool) → Y1 (Diversity rate ↑)
X2 (Structured processes) → M2 (Reduced bias) → Y1 (Diversity rate ↑) + Y2 (Quality maintained)
X3 (Voluntary + transparency) → M3 (Intrinsic motivation) → Y1 (Sustained diversity gains)

Evidence: Ameri & Kurtzberg (2025) RCT showed heartfelt language increased diverse applicant interest 12 points; Hardy et al. (2022) meta-analysis showed structured interviews reduced bias 0.43 SD; practitioner evidence confirms voluntary > mandates

EVALUATION DESIGN

Evaluation Questions
1. Implementation Fidelity: Was intervention implemented as intended? (90%+ interview compliance, 100% job posting compliance, 80%+ blind review)
2. Outcome Achievement: Did diversity rate reach 29%+? Quality maintained ≥4.0? Candidate experience improved?
3. Mechanism Verification: Did change happen through expected mediators (M1, M2, M3)?
4. Sustainability: Can initiative be sustained at ~$15,700/year ongoing cost?

Design Approach
Type: Pre/Post Comparison with Time Series + Mixed Methods
Timeline: 6-month baseline (Months -6 to 0) + 12-month implementation/evaluation (Months 1-12)
Strengths: Multiple time points establish baseline stability; monthly tracking detects trends; mixed methods explain what and why
Limitations: No control group; self-selection bias in voluntary training
Mitigation: Benchmark against industry diversity trends; compare training participants vs. non-participants

KEY PERFORMANCE INDICATORS (KPIs)

Implementation KPIs
Job Posting Compliance: 100% use heartfelt DEI language | Monthly audit (10% sample) | ATS + manual review
Interview Guide Usage: 90%+ structured interview adoption | Monthly audit + manager self-report
Blind Review Adoption: 80%+ resumes processed via blind review | ATS automated tracking
Training Participation: 50%+ managers complete voluntary training by Month 12 | Attendance records
Dashboard Engagement: Leadership reviews monthly, 100% compliance | Meeting attendance

Outcome KPIs
Diversity Hiring Rate: 29%+ by Month 12 (from 24% baseline) | Monthly HRIS data
Quality of Hire: Maintain ≥4.0/5.0 (from 4.0 baseline) | Quarterly 90-day manager ratings
Candidate Experience: ≥4.2/5.0 all groups (from 3.2-3.9 baseline) | Continuous post-interview surveys
Manager Satisfaction: 80%+ rate tools ≥4.0/5.0 | Quarterly manager surveys
Applicant Pool Diversity: 3+ percentage point increase | Monthly ATS applicant demographics

Mediator KPIs
M1 - Diverse Applicant Pool %: 3+ point increase from baseline | Monthly ATS tracking
M2 - Bias Awareness Scores: 30%+ improvement pre/post training | Training pre/post tests
M3 - Intrinsic Motivation Index: SDT scale scores ≥4.0/5.0 | Quarterly manager survey

Fidelity KPIs
Content Fidelity: Interview guides include all required elements - 100% target
Dose Fidelity: Managers use guides for full interview - 90% target (random observation)
Quality Fidelity: Interview scores show adequate variance - assessed via score distribution
Participant Responsiveness: Managers report tools helpful ≥4.0/5.0 - quarterly measurement

DATA COLLECTION PLAN

Quantitative Data
HRIS Demographics: Monthly extract, diversity rates and new hire demographics | Monthly trend charts, t-tests at Month 12
Quality Ratings: 90-day manager surveys, ~10 hires/month, 5-point scale | Quarterly averages, pre/post t-tests
Candidate Surveys: Post-interview, ~50 candidates/month, 40% response, 6-question scale | Monthly averages by demographic, gap analysis
Training Pre/Post Tests: 10-question bias awareness, all participants (~50 managers) | Paired t-tests for knowledge gain
ATS Compliance Data: Automated tracking of blind review, job posting usage | Monthly compliance %, trend analysis

Qualitative Data
Manager Focus Groups: Month 8, n=10 (5 trained, 5 not), 90-min sessions on tool usefulness, barriers, motivation
Candidate Interviews: Month 10, n=8 underrepresented candidates, 30-min phone interviews on authenticity and experience
Implementation Observations: Random 5% sample of interviews observed (with consent), Months 6-8, assess fidelity
Document Review: Sample 20 interview scorecards quarterly, assess quality and consistency

Mixed Methods Integration
Convergence: Triangulate diversity improvements with manager behavior reports and candidate fairness perceptions
Explanation: Use qualitative data to explain quantitative trends (e.g., if diversity increased, what did managers say helped?)
Divergence Investigation: If quantitative and qualitative conflict, investigate through additional inquiry

SUCCESS CRITERIA & INTERPRETATION

Must-Achieve (Failure if not met)
1. Diversity rate ≥27% by Month 12 (3+ point increase shows directional progress)
2. Quality of hire ≥3.8/5.0 (no significant decline from 4.0 baseline)
3. Implementation fidelity 80%+ compliance with at least 2 of 3 intervention components

Should-Achieve (Important for full success)
1. Diversity rate reaches 29%+ target
2. Candidate experience ≥4.0 all groups (narrowing gap)
3. Manager satisfaction ≥75% rate tools helpful
4. 50%+ manager training participation

Could-Achieve (Stretch goals)
1. Diversity rate exceeds 30%
2. Quality improves beyond 4.0 baseline
3. 75%+ manager training participation
4. Improved employer brand metrics (Glassdoor ratings)

Interpretation Framework
Strong Success: Primary outcome 29%+, quality maintained, high fidelity, positive stakeholder feedback
Moderate Success: Primary outcome 27-28%, quality maintained, moderate fidelity—refinement needed but approach sound
Weak/Failure: Primary outcome <26%, quality decline, low fidelity—fundamental redesign or discontinuation needed

Unintended Consequences to Monitor
Positive Possibilities: Improved employer brand, better retention of diverse employees, peer organization adoption
Negative Risks: Tokenization perceptions, manager resentment, "diversity vs. quality" narrative, legal challenges
Monitoring: Track Glassdoor reviews monthly, employee climate survey (Month 12), media mentions, legal inquiries

REPORTING & CONTINUOUS IMPROVEMENT

Reporting Schedule
Monthly: Dashboard to leadership (diversity rate, quality, compliance, 1-page summary)
Quarterly: All-manager update email (progress, success stories, Q&A)
Bi-Annual: Strategic review with C-suite (Month 6: mid-point; Month 12: final evaluation with recommendations)

Decision Points
Month 4 (Post-Pilot): Go/No-Go on full rollout based on pilot fidelity ≥80%, no quality decline, manager satisfaction ≥3.5/5.0
Month 6 (Mid-Point): Continue as-is OR modify components OR intensify efforts based on diversity trend direction
Month 12 (Final): Sustain, scale, or sunset based on must-achieve criteria met + cost-benefit analysis

Continuous Improvement
Monthly Cycle: Dashboard review → identify gaps → rapid troubleshooting → adjust tools/support
Quarterly Feedback: Manager surveys → identify usability issues → revise templates → communicate updates
Annual Refresh: Comprehensive evaluation → update evidence base → refine intervention → plan Year 2

Sustainability Assessment (Month 12)
Viability Indicators: Diversity gains sustained Months 9-12, manager survey shows tools "integrated into routine" ≥70%, ongoing cost ≤$20K/year feasible
Institutionalization: Embed tools in manager onboarding, establish quarterly dashboard as standing leadership agenda item, create peer mentor network
Knowledge Management: Document lessons in centralized repository, create video tutorials, assign process ownership to HR BP role
